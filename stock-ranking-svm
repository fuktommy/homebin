#!/usr/bin/python
"""Stock ranking using http://k-db.com/

Requires libsvm3 and python-libsvm.
"""
#
# Copyright (c) 2013 Satoshi Fukutomi <info@fuktommy.com>.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
# 1. Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
#
# THIS SOFTWARE IS PROVIDED BY THE AUTHORS AND CONTRIBUTORS ``AS IS'' AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHORS OR CONTRIBUTORS BE LIABLE
# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
# OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
# OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
# SUCH DAMAGE.
#

from __future__ import division
import codecs
import csv
import math
import optparse
import os
import sys
import time
import urllib2

import svm
import svmutil


def parse_args(argv):
    """Parse command line argments.
    """
    default_workdir = os.path.expanduser('~/.stock-ranking')
    usage = 'usage: %prog [options] [string...]'
    parser = optparse.OptionParser(usage=usage)
    parser.add_option('-d', '--workdir', dest='workdir',
                      default=default_workdir, metavar='PATH',
                      help='working directory')
    parser.add_option('-e', '--encode', dest='output_encode',
                      default='utf-8',
                      help='output_encoding')
    parser.add_option('-f', '--fetch', action='store_true', default=False,
                      dest='do_fetch',
                      help='fetch from http://k-db.com/')
    parser.add_option('-r', '--remove', action='store_true', default=False,
                      dest='do_remove',
                      help='remove old files')
    parser.add_option('-t', '--threshold', dest='threshold', type='float',
                      default=1.01, help='price ratio threshold')
    parser.add_option('--test', action='store_true', default=False,
                      dest='test_mode',
                      help='parameter test mode')
    return parser.parse_args(argv)


class DataSource(object):
    def __init__(self, date, workdir):
        """Create data source by date(YYYY-MM-DD)
        """
        self.date = date
        self.workdir = workdir
        self.basename = '%s_all.csv' % date
        self.path = os.path.join(workdir, self.basename)
        self.url = ('http://k-db.com/site/download.aspx'
                 + '?p=all&download=csv&date=' + date)

    def is_fetched(self):
        return os.path.isfile(self.path)

    def fetch(self):
        sys.stderr.write('fetching %s\n' % self.url)
        buf = urllib2.urlopen(self.url).read()
        if not buf.startswith(self.date):
            sys.stderr.write('skip %s\n' % self.url)
        if not os.path.isdir(self.workdir):
            os.makedirs(self.workdir)
        open(self.path, 'w').write(buf)
        time.sleep(1)


def get_dates(now):
    dates = []
    for i in xrange(0, 20):
        d = now - i * 24 * 60 * 60
        day = time.strftime('%w', time.localtime(d))
        if day in ('0', '6'):
            # Sunday or Saturday
            continue
        dates.append(time.strftime('%Y-%m-%d', time.localtime(d)))
    dates.reverse()
    return dates

def remove_old_files(sources, workdir):
    if not os.path.isdir(workdir):
        return
    expected_files = [s.basename for s in sources]
    for f in os.listdir(workdir):
        if f not in expected_files:
            path = os.path.join(workdir, f)
            sys.stderr.write('removing %s\n' % path)
            os.remove(path)


class Stock(object):
    def __init__(self, code, name):
        self.code = code
        self.name = name
        self._ratio = {}
        self.label = 0
        self.vectors = []

    def add(self, row):
        try:
            self.vectors.append([self._strtoint(i) for i in row[4:]])
        except (IndexError, ValueError):
            pass

    def _strtoint(self, str):
        if str == '' or str == '-':
            return -1
        else:
            return int(str)

    def get_ratio(self, day_sub = 0):
        if day_sub in self._ratio is not None:
            return self._ratio[day_sub]
        try:
            min0 = self.vectors[-1 - day_sub][-4]
            sales0 = self.vectors[-1 - day_sub][-1]
            turnover0 = self.vectors[-1 - day_sub][-2]
            min1 = self.vectors[-2 - day_sub][-4]
            sales1 = self.vectors[-2 - day_sub][-1]
            turnover1 = self.vectors[-2 - day_sub][-2]

            if min(min0, min1) < 100:
                self._ratio[day_sub] = 0
                return self._ratio[day_sub]

            self._ratio[day_sub] = (sales0 / turnover0) / (sales1 / turnover1)
            return self._ratio[day_sub]
        except (IndexError, ValueError, ZeroDivisionError):
            self._ratio[day_sub] = 0
            return self._ratio[day_sub]

    def _get_kcom_code(self):
        return (self.code.replace('-', '.')
                .replace('.O', '.OS')
                .replace('.J', '.OS')
                .replace('.S', '.SP'))

    def get_kcom_url(self):
        return ('http://s20.si0.kabu.co.jp/Members/Tradetool/investment_info/?'
                + 'trid=600&trric=' + self._get_kcom_code())


class StockMap(object):
    def __init__(self):
        self.map = {}
        self.threshold = 0

    def read(self, csvfile):
        for row in csv.reader(open(csvfile)):
            try:
                code = row[0]
                name = row[1].decode('sjis')
                int(row[4])
            except (IndexError, ValueError):
                continue
            if code not in self.map:
                self.map[code] = Stock(code, name)
            self.map[code].add(row)

    def _flatten(self, vectors):
        ret = []
        prev = None
        for vector in vectors:
            v = vector[:]
            v.append(v[-1] / v[-2])
            if prev:
                ret.extend([v[i] / prev[i] for i in range(len(prev))])
            prev = v
        return ret

    def run_svm(self, threshold, test_mode):
        train_labels = []
        train_data = []
        correct_data = []
        ref_labels = []
        codes = self.map.keys()
        if test_mode:
            sub_diff = 2
        else:
            sub_diff = 0

        threshold_count = 0
        threshold_count_ref = 0
        for code in codes:
            stock = self.map[code]
            if stock.get_ratio(sub_diff) >= threshold:
                train_labels.append(1)
                threshold_count += 1
            else:
                train_labels.append(-1)

            if not test_mode:
                pass
            elif stock.get_ratio() >= threshold:
                ref_labels.append(1)
                threshold_count_ref += 1
            else:
                ref_labels.append(-1)

            train_data.append(self._flatten(stock.vectors[: -2 - sub_diff]))
            correct_data.append(
                self._flatten(stock.vectors[2 + sub_diff : - sub_diff]))

        if not test_mode:
            ref_labels = [-1 for i in correct_data]

        print ('%d items. %d items has ratio larger than %f.' %
            (len(codes), threshold_count, threshold))
        if test_mode:
            print ('%d items has ratio larger than %f. in test data.' %
                (threshold_count_ref, threshold))

        problem = svm.svm_problem(train_labels, train_data)
        parameter = svm.svm_parameter('-s 0 -t 2 -h 0')
        t = svmutil.svm_train(problem, parameter)
        result = svmutil.svm_predict(ref_labels, correct_data, t)
        i = 0
        for code in codes:
            self.map[code].label = result[0][i]
            i += 1

def _main():
    options, args = parse_args(sys.argv[1:])
    sys.stdout = codecs.getwriter(options.output_encode)(sys.stdout)
    workdir = options.workdir
    sources = [DataSource(d, workdir) for d in get_dates(time.time())]
    if options.do_remove:
        remove_old_files(sources, workdir)
    stock_map = StockMap()
    for s in sources:
        if options.do_fetch and not s.is_fetched():
            s.fetch()
        if s.is_fetched():
            stock_map.read(s.path)
    stock_map.run_svm(options.threshold, options.test_mode)
    for s in stock_map.map.values():
        if s.label == 1.0:
            print s.name, s.get_kcom_url()

if __name__ == '__main__':
    _main()
