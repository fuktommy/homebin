#!/usr/bin/python3
'''Report or omit repeated files.

usage: filediet [-n] directory...
options: -n: show what would have been removed
'''
#
# Copyright (c) 2006-2019 Satoshi Fukutomi <info@fuktommy.com>.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
# 1. Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
#
# THIS SOFTWARE IS PROVIDED BY THE AUTHORS AND CONTRIBUTORS ``AS IS'' AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHORS OR CONTRIBUTORS BE LIABLE
# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
# OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
# OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
# SUCH DAMAGE.
#

import random
import shutil
import sys
import os
import hashlib

#
# Config
#
TRASH = os.path.expanduser('~/Trash/.')
CACHE = 'MD5CACHE'

class MD5Cache:
    '''MD5 Cache File.

    One file par one directory.
    '''

    def __init__(self, dirname):
        self.hash = {}
        self.dirname = dirname
        self.cachefile = os.path.join(dirname, CACHE)
        if os.path.isfile(self.cachefile):
            for line in open(self.cachefile):
                line = line.strip()
                self.hash[line[34:]] = line[:32]

    def sync(self):
        fp = open(self.cachefile, 'w')
        for key, value in self.hash.items():
            fp.write('%s  %s\n' % (value, key))

    def update(self, files):
        '''Read files and cache MD5 digest.

        Files is a list of file basenames.
        '''
        for key in list(self.hash.keys()):
            if not os.path.isfile(os.path.join(self.dirname, key)):
                del self.hash[key]
        for f in files:
            if (f != CACHE) and (f not in self.hash):
                path = os.path.join(self.dirname, f)
                hash = hashlib.md5()
                hash.update(open(path, 'rb').read())
                self.hash[f] = hash.hexdigest()

    def __iter__(self):
        for key, value in self.hash.items():
            yield os.path.join(self.dirname, key), value

# End of MD5Cache


class SortFunc:
    def __init__(self, hash, path):
        self.hash = hash
        self.path = path

    def __lt__(self, b):
        return self.cmp(b) < 0

    def __gt__(self, b):
        return self.cmp(b) > 0

    def __eq__(self, b):
        return self.cmp(b) == 0

    def cmp(self, b):
        buf = self._cmp(self.hash, b.hash)
        if buf:
            return buf
        buf = self._cmp(os.path.dirname(self.path), os.path.dirname(b.path))
        if buf:
            return buf
        ba = os.path.basename(self.path)
        bb = os.path.basename(b.path)
        buf = self._cmp(len(ba), len(bb))
        if buf:
            return buf
        buf = self._cmp(ba, bb)
        return buf

    def _cmp(self, a, b):
        if a < b:
            return -1
        elif a > b:
            return 1
        else:
            return 0

# End of SortFunc


def samefile(a, b):
    if os.path.getsize(a) != os.path.getsize(b):
        return False
    fa = open(a, 'rb')
    fb = open(b, 'rb')
    while True:
        ba = fa.read(1)
        bb = fb.read(1)
        if (not ba) and (not bb):
            return True
        elif ba != bb:
            return False

def main():
    hash = {}       # hash[filename] == md5digest
    if not os.path.isdir(TRASH):
        os.makedirs(TRASH)
    targets = []
    dry_run = False
    buf = sys.argv[1:]
    while buf:
        i = buf.pop()
        if i == '-n':
            dry_run = True
        elif i == '--':
            targets.extend(buf)
        else:
            targets.append(i)
    if not targets:
        sys.exit('usage: filediet [-n] directorys')

    # update caches.
    for i in targets:
        for dirpath, dirnames, filenames in os.walk(i):
            cache = MD5Cache(dirpath)
            cache.update(filenames)
            cache.sync()
            for key, value in cache:
                hash[key] = value

    filenames = list(hash.keys())
    filenames.sort(key=lambda x: SortFunc(hash[x], x))

    # remove files.
    if filenames:
        last = filenames.pop(0)
    for f in filenames:
        if (hash[last] == hash[f]) and samefile(last, f):
            print(f)
            if not dry_run:
                dst = '%d_%s' % (random.randint(0, 1000), os.path.basename(f))
                shutil.move(f, os.path.join(TRASH, dst))
        else:
            last = f


if __name__ == '__main__':
    main()
